{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/blog/train-sparse-encoder\n",
    "\n",
    "https://github.com/UKPLab/sentence-transformers/blob/master/examples/sparse_encoder/applications/retrieve_rerank/hybrid_search.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸ºä»€ä¹ˆä½¿ç”¨ç¨€ç–åµŒå…¥æ¨¡å‹ï¼Ÿ\n",
    "ç®€è€Œè¨€ä¹‹ï¼Œç¥ç»ç¨€ç–åµŒå…¥æ¨¡å‹åœ¨ BM25 ç­‰ä¼ ç»Ÿè¯æ±‡æ–¹æ³•å’Œ Sentence Transformers ç­‰å¯†é›†åµŒå…¥æ¨¡å‹ä¹‹é—´å æ®ç€ä»¥ä¸‹ä¼˜åŠ¿ï¼š\n",
    "\n",
    "æ··åˆæ½œåŠ›ï¼šä¸å¯†é›†æ¨¡å‹éå¸¸æœ‰æ•ˆåœ°ç»“åˆï¼Œåœ¨è¯æ±‡åŒ¹é…å¾ˆé‡è¦çš„æœç´¢ä¸­å¯èƒ½ä¼šé‡åˆ°å›°éš¾\n",
    "å¯è§£é‡Šæ€§ï¼šä½ å¯ä»¥å‡†ç¡®åœ°çœ‹åˆ°å“ªäº›æ ‡è®°æœ‰åŠ©äºåŒ¹é…\n",
    "æ€§èƒ½ï¼šåœ¨è®¸å¤šæ£€ç´¢ä»»åŠ¡ä¸­å…·æœ‰ç«äº‰åŠ›æˆ–ä¼˜äºå¯†é›†æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SparseEncoder\n",
    "\n",
    "# Download from the ğŸ¤— Hub\n",
    "model = SparseEncoder(\"naver/splade-v3\")\n",
    "\n",
    "# Run inference\n",
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "# (3, 30522)\n",
    "\n",
    "# Get the similarity scores for the embeddings\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n",
    "# tensor([[   32.4323,     5.8528,     0.0258],\n",
    "#         [    5.8528,    26.6649,     0.0302],\n",
    "#         [    0.0258,     0.0302,    24.0839]])\n",
    "\n",
    "# Let's decode our embeddings to be able to interpret them\n",
    "decoded = model.decode(embeddings, top_k=10)\n",
    "for decoded, sentence in zip(decoded, sentences):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Decoded: {decoded}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼ŒåµŒå…¥æ˜¯ 30,522 ç»´å‘é‡ï¼Œå…¶ä¸­æ¯ä¸ªç»´åº¦å¯¹åº”äºæ¨¡å‹è¯æ±‡è¡¨ä¸­çš„ä¸€ä¸ªæ ‡è®°ã€‚è¯¥decodeæ–¹æ³•è¿”å›äº†åµŒå…¥ä¸­å€¼æœ€é«˜çš„ 10 ä¸ªæ ‡è®°ï¼Œè¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿè§£è¯»å“ªäº›æ ‡è®°å¯¹åµŒå…¥çš„è´¡çŒ®æœ€å¤§ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SparseEncoder\n",
    "\n",
    "model = SparseEncoder(\"naver/splade-cocondenser-ensembledistil\")\n",
    "\n",
    "model = SparseEncoder(\"google-bert/bert-base-uncased\")\n",
    "# SparseEncoder(\n",
    "#   (0): MLMTransformer({'max_seq_length': 512, 'do_lower_case': False, 'architecture': 'BertForMaskedLM'})\n",
    "#   (1): SpladePooling({'pooling_strategy': 'max', 'activation_function': 'relu', 'word_embedding_dimension': None})\n",
    "# )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
